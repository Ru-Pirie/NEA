\begin{flushleft}
    \section{Analysis} 
        \subsection{Statement Of Problem}
        \large
        \bk
        Maps, as you would think of them today, have been around since 6\textsuperscript{th} century BC and since then have been in constant use by people in their day to day lives. 
        The more modern version of maps, for example Google maps or Bing maps have only been around since the late 1990's. The problem that I am going to be solving is map path finding.
        Currently not all roads and paths are logged and entered into a searchable format. The only way some people have to navigate terrain is through the use of old style paper maps.
        The problem with paper maps is that they are not easily, at a glance, used to find a path from point to point. As well as this sometimes are not easy to comprehend just by looking 
        at them with various terrain features. \\
        
        \bk
        \begin{figure}[h]
            \centering
            \subfloat[\centering Map without labels on roads]{{\includegraphics[width=6cm]{images/unlabeledMap.png}}}
            \qquad
            \subfloat[\centering Map with labels on roads]{{\includegraphics[width=6cm]{images/labeledMap.png}}}
            \caption*{Examples of maps with and without labels taken from Google Maps\textsuperscript{\textcopyright}}
        \end{figure}
        \bk

        This can cause issues for people who live out in areas which have not been mapped. This is because they cannot create easy to follow routes with the click of a button. Therefor, 
        causing people who live in rural areas to waste time getting used to the routes they have to take to go anywhere. Overall, the problem I am going to be creating a solution for is 
        how people are unable to easily go from point to point at the click of a button and be easily able to, at a glance, interpret the map without prior experience. \\

        \subsection{Background}
        \bk
        When people usually want to go about planning a journey they will use a service, for example Google Maps to get from one location to another. This usually takes the form of clicking 
        a location and then selecting an origin. This isn't always possible however, this can be for a multitude of reasons it seems however I will briefly go over some below:\\
        
        \begin{enumerate}
            \item \textbf{Either the destination or origin location(s) are not in the service's database.}
            \item \textbf{The destination and origin have no clear defined path between them.}
            \item \textbf{Either the destination or origin are off any predefined track.}
            \item \textbf{The travel method the user has selected is not able to traverse the terrain between the origin and destination.}
        \end{enumerate}

        \bk
        Some of these I believe are out of the scope of this project however once the interview has been conducted with the end user I will have a better idea of the needs that my program needs to for-fill.\\

        \bk
        Finally, 

        \bk
        
        \subsection{End User}
            \subsubsection{First Interview}
            \large
            In order to get a better feel for the objectives and functions that my program should complete I interviewed with an end user, Mrs Mandy T. I believed that she was an appropriate candidate for this
            project due to the fact that she has to drive into work every morning. Along her route she has to deal with Google Maps which do not cover all of the roads in her area. Therefor in the following questions
            I asked her some questions gauge her priorities when it comes to web mapping.
            \bk
            \begin{enumerate}
                \item {\bf{When using web maps (e.g. Google Maps\textsuperscript{\tiny\textcopyright}) what are the key features you look for?}} \\
                \bk
                "A scale! WHY is it lost so often when Google Maps is embedded?! 
                Then it depends what type of map I'm looking at... if it's a road map then....roads! Size/type of road is important and things like one-way restrictions. 
                If it's for e.g. walking...footpaths/bridleways and parking are important. 
                "
                \item {\bf{Have you ever experienced a faulty or mislabeled part of an web map or has said map ever been inaccurate?}} \\
                \bk
                "Yes"
                \item {\bf{Do you often use web maps in your day to day life, if so how?}} \\
                \bk
                "Yes, \textbf{NEEDS TO BE ADDED TO}"
                \item {\bf{In your opinion do you feel that web maps are vital to every day life if so why or why not? }} \\
                \bk
                "No.  I passed my driving test before we had sat-nav or internet, so clearly they're not vital - we survived without them! \\ 
                They are quite helpful though as we used to have to buy a new road map every year, whereas web maps can be updated as things change, instead of only annually!"
                \item {\bf{What makes a good user interface for a web map?}} \\
                \bk 
                "Clarity and simplicity.  Nothing needlessly complicated."
                \item {\bf{How do you use web maps (e.g. long journeys, short journeys, school runs)?}} \\
                \bk
                "Route functionality on long or unfamiliar journeys. 
                Using them a lot at the moment as am planning a holiday overseas.  The maps are useful to see whether accommodation and restaurants will be walking distance, 
                and what options there are in each location etc."
                \item {\bf{Do you feel a tutorial would be beneficial to aid in the use of the map or should the focus more be spent on intuitive ease of use?}} \\
                \bk
                "If they're easy to use, a tutorial would be surplus to requirements, so ease of use is more important. "
                \item {\bf{Would it be beneficial to store old routes?}} \\
                \bk
                "Not really (is this a routing question?). I don't know what purpose that would give, unless I was being accused of something and needed to use the route as evidence of 
                being in a certain location! It could be use full in the context of frequently traveled routes however if this was the case I would know the route by heart anyway."
                \item {\bf{What forms of transport should the map include?}} \\
                \bk
                "(I think this is a routing question not a map question)
                Walking, bike/horse, car, bus, plane, ferry. 
                If just a map question, then the map should include footpaths, bridle paths, roads, ferry routes"
                \item {\bf{If there was one feature you could have implemented in an existing solution what would it be?}} \\
                \bk
                "To be able to post a question about a specific area and have a person who is local to that area answer it."
            \end{enumerate}
            
            \subsubsection{Evaluation of First Interview}
            Overall I feel that this interview gave me valuable insight into the requirements of my end user. As well as this my end user made it clear to me that there are two overriding 
            parts of this solution. The map recognition aspect of it and the path finding aspect. Going deeper into the path finding part of this project I will need to do research on the 
            different methods that will be used to achieve this and some of the possible data structures I could use. \\
        \bk

        \subsection{Initial Research} 
            \subsubsection{Existing Solutions}
            Below each overview passage I have included an image of each map for comparison of their GUI's. These will be used as inspiration as to how my final solution will look as well 
            as serving as examples of how the GUI can sometimes become overly complicated. This is especially the case with Bing Maps as when you initially access it you are flooded with 
            popups and extra options. \\
            \paragraph{Google Maps} \mbox{} \\
            \bk
            
            As aforementioned this is one of the most used forms of interactive web mapping in use at the moment. It has been in use since 8\textsuperscript{th} February 2005. As it exists
            now it is an interactive world map with routing features built in. It provides detailed information about geographical places and regions around the world. Unlike some of its
            competitors it also offers aerial and satellite images of places around the world aiding in navigation of terrain. \\
            
            \bk
            
            As well as its map viewing capabilities it also offers partial route planning and live route tracking for cars, bikes, walkers and public transport. It provides instantaneous and
            real time feedback while you are moving however the one big caveat to this is the fact that it will require an internet connection to run, something that is not always available. \\
            \bk
            
            \begin{figure}[H]
                \centering
                \subfloat[\centering Example of Google Maps' GUI]{{\includegraphics[width=7.5cm]{images/googleMapExample.png}}}
                \caption*{Sourced from Google Maps\textsuperscript{\tiny\textcopyright}}
            \end{figure}

            \bk 
            
            \paragraph{Bing Maps} \mbox{} \\
            This is another form of interactive web mapping. This is a more plain version of Google Maps at first glace. This is due to the fact that it does not have as many features as Google Maps.
            This does have its advantages due to the UI seeming less cluttered and more accessible. Similar to the Google Maps it also offers route planning and map traversal as well as live traffic updating.
            Bing maps unlike Google Maps boasts a more open API and easier programmatic interface for developers to be able to interface with their program. \\
 
            \bk
 
            Bing maps also still includes the feature which allows users to create their own maps based on their own data. Unlike google which did have this feature until they discontinued it.
            I believe that this could be something that would be beneficial to my program, allowing people to take a photo of their own map and have my solution compute it into a routable map. \\
 
            \bk
 
            \begin{figure}[H]
                \centering
                \subfloat[\centering Example of Bing Maps' GUI]{{\includegraphics[width=7.5cm]{images/bingMapExample.png}}}
                \caption*{Sourced from Bing Maps\textsuperscript{\tiny\textcopyright}}
            \end{figure}

            \bk

            \paragraph{OS Maps} \mbox{} \\
            This is a different take in web mapping compared to Bing and Google Maps. With Ordnance Survey their focus was on the accuracy of their maps hence they do not have as an extensive routing system.
            If you wanted to go from point to point on an OS map you would have to plot it by hand. However if you wanted to go on an exercise trail on the other hand they are very well suited
            for this and as such have an extensive list of pre-planned routes. \\
            \bk
            Similar to Google Maps, and in a limited capacity, Bing maps; OS Maps allow you to view their maps in different forms such as 3D and topographic however in order to access these you will
            have to access their premium plan therefor for the average user this is not a viable option and a hindrance. It is good to note however that the other variations on the map of the UK,
            and this holds true for all of the aforementioned maps, that the satellite view and other views are not necessary and could in fact be a hindrance. \\
            
            \bk
            
            \begin{figure}[H]
                \centering
                \subfloat[\centering Example of Ordnance Survey's Map GUI]{{\includegraphics[width=7.5cm]{images/osMapExample.png}}}
                \caption*{Sourced from OSMaps.com\textsuperscript{\tiny\textcopyright}}
            \end{figure}

            \bk
            
            \paragraph{Existing Solutions Conclusion} \mbox{} \\
            In conclusion, I have found that the existing solutions that are available are all very well designed and well implemented. I have found that they are easy to use and rather intuitive
            however, for the average user who just needs to get from A to B in the most economic way possible they are overly complicated. As well as this I have found that with the exception of OS maps
            both of the other solutions require an internet connection to get the best use out of their maps, this is something which I believe I should avoid. This will mean that all calculations will 
            have to occur self contained within the program, not allowing the use of external API's. \\
            \bk

            \subsubsection{Possible Algorithmic Solutions}
            There are, as aforementioned many existing solutions which work in various ways, in order to make my solution unique and functioning I am going to have to incorporate many different algorithms
            and theories. \\ \bk

            \paragraph{Edge Detection} \mbox{} \\
            First of all I will need some way of recognising a map and parsing it in some way. The way that first springs to mind is edge detection. This is a way of taking an image and computing where there
            are changes in contrast or brightness which could be considered an edge. There are many forms of edge detection out there all of which work in various ways, the main things they look for however
            are discontinuities in depth, discontinuities in surface orientation, changes in material properties and variations in scene illumination. All of these factors combine and allow a program to decide
            if there is an edge in an image. \\ \bk

            A simple edge detection model can be extremely effected by natural blur or artifacts in an image. In order to mitigate this there are smoothing algorithms that can be used to blur and smooth edges
            causing the impact of artifacts to be avoided. The common term when referring to artifacts and erroneous data in an image is \emph{noise}. I believe it will be beneficial to include some of these
            in my solution, this will be something to look into in the \textbf{Further Research} section. \\ \bk

            Taking a quick look at one form of edge detection, Canny Edge detection, it is relatively simple in its implementation. It has only 5 steps, first removing noise with a Gaussian filter then applying
            bounding to the image and finally performing hysteresis threshold. This is the most common form of edge detection that I have come across in my research however there are others. A rather
            different example of edge detection is Kovalevsky edge detection. Unlike canny edge detection this does not care about the luminosity of the image and goes based of the colour intensity in each
            of the channels. \\ \bk

            \paragraph{Graph Forming} \mbox{} \\
            This is not so much a possible algorithmic solution but more of something that my solution will have to achieve. Once the image of the map has been altered and the edge detection has been 
            performed, I will be left with an image which has white lines where there "edges". From this I will need to create a weighted graph as well as an unweighted graph. \\ \bk
            
            During my research I have failed to come across an existing solution to this problem. As well as this looking through some examples that people have uploaded it seems that sometimes the edge 
            detection does not yield a fully connected image. This could prove to be an issue as it would add the possibility of isolating certain roads. \\ \bk
            
            I feel that I need to look more into this and come up with my own solution during the prototyping stage, and come up with my own algorithmic way of generating it. \\ \bk
            
            \bk

            \subsubsection{Key Components Required}
            After doing my initial research and a brief look at the existing solutions I have come up with, what I feel, is the main 4 Components that I will need to build my solution. \\ \bk
            
            \paragraph{The Graphical User Interface} \mbox{} \\
            Talking to my end user made it clear to me that in order for the program to be usable by the wider population it would need to be clean and uncluttered. This leaves me in a difficult position 
            due to there being a limited amount of frameworks that are available to me. I have two sets of possibilities: \\
            \begin{enumerate}
                \item A Local App Run on Device
                \item A Web Based Application
            \end{enumerate}
            Each of these have their advantages, if I where to go with a locally run app I could make it in the console keeping it simplistic and easy to use. However if I do use the console it would limit
             this solution to a computer which could be seen as going against the idea of this problem. On the other hand, if I where to go with a web server based application this would yield much better 
             compatibility with all devices since all you would need is access to a web browser. This, by its very nature, means that you would need an internet connection which is also a problem which I
              was hoping to fix. \\ \bk
            
            The solution then I believe is to make it both a locally based program with the option for it to run a web server. However I will need to specify one over the other to begin with to make sure
             that the program is working either way. \\ \bk
            
            Regardless of which one I choose I will conduct some form of testing where I will allow, through a survey, people to specify what makes an easy to use and intuitive. \\ \bk
            
            \paragraph{Image Manipulation and Edge Detection} \mbox{} \\
            This is perhaps the most important part of the project since without this I would not be able to continue to path find the image of the map. Looking at my research I feel that there will be a combination of 
            \bk
            
            \paragraph{Graph Creation and Representation} \mbox{} \\
            From lessons which we have had in class I have been shown that there are 2 reasonable ways of representing a graph in code, this includes an adjacency matrix and an adjacency list. Both have their advantages and disadvantages. An adjacency matrix is good when you have a reasonably connected graph which has weights, this is due to it being easy to access and traverse. As soon as you have a sparse graph however it becomes very memory intensive which is unnecessary considering that there will be very few of the cells with actual data in them. This is when the adjacency list comes into play, the reason that I am reluctant to use this form of representing a graph is that when performing some of the various graph traversal algorithms it can incredibly difficult and pointless to adapt them when by adapting them you effectively generate the adjacency matrix.
            \bk
            
            \paragraph{Graph Traversal and Output} \mbox{} \\
            \bk


        \subsection{Further Research}
            \subsubsection{Dive into Specific Algorithms}
            After doing some research it seems that there needs to be a set of definitions before I go any further to avoid confusion. This is because during my time on Wikipedia there are sections
            where several terms are used interchangeable where I feel they are not the same. Each of these definitions are as defined by me and are not necessarily the official definitions since they 
            do not explicitly exist. They are as follows: \\ \bk
            \begin{enumerate}
                \item Graph Traversal: The act of routing or searching through a graph from one node to another, either using an algorithm or by another means.
                \item Graph Routing: Graph traversal in a \emph{weighted undirected} graph.
                \item Graph Searching: Graph traversal in a \emph{unweighted undirected} graph.
                \item Graph MST: The minimum spanning tree of a graph which must be weighted.
            \end{enumerate}

            \bk
            The difference is slight however the key takeaway from this is that when I am referring to a Routing algorithm I am referring to one which works on a weighted graph. And vice versa if I am 
            talking about a searching algorithm this is referring to graph traversal on an unweighted graph. \\ \bk

            \paragraph{Black and White Filter}\mbox{} \\
            In order to allow the program to function, assuming that the canny edge detection was chosen we do not need the colour data of the image. In order to remove this a filter is used, this one is the
            industry standard since it takes into account how prevalent red, green and blue are rather than taking an average which could become non representing of the real case. \\ \bk
            
            \begin{gather*}
                \beta = 0.299 * \alpha_{b} + 0.587 * \alpha_{g} + 0.114 * \alpha_{b}
                \text{; }
                \begin{cases}
                    255 & \beta > 255 \\
                    0 & \beta < 0 \\
                    \beta & \beta \in [0, 255]
                \end{cases}
            \end{gather*}
            
            \BK

            If an averaging was used it would just be, this is also known colloquially as the "quick and dirty" method. \\ \bk
            \begin{gather*}
                    \beta = \frac {(\alpha_{b} + \alpha_{g} + \alpha_{b})}{3}
            \end{gather*}

            \bk
            \paragraph{Gaussian Filter} \mbox{} \\
            This is the first step of 5 in terms of performing Canny Edge Detection. Applying the Gaussian filter to the image will smooth out the image and remove any noise. It does this by taking a section
            of the image, sometimes referred to as a kernel and performing an equation on it. Once it has computed the equation it sets all of the pixels inside the kernel to this value. The following is true 
            for a kernel size of $(2k + 1) * (2k + 1)$. It takes two changeable parameters $\sigma$ which denotes the amount of blur to apply and $k$ is the kernel size. As well as being one of the key steps in canny edge detection it is also a vital component to most edge detection programs since noise can caise errors in the final image.\\ \bk
            
            \begin{gather*}
                H_{ij} = \frac{1}{
                    2\pi\sigma^{2}
                } \exp \bigg(
                    -\frac{
                        (i - (k + 1))^{2} + (j - (k + 1))^{2}
                    }
                    {
                        2\sigma^{2}
                    }
                \bigg);1\leq i, j \leq(2k+1)
            \end{gather*}

            \BK
            Since the Gaussian kernel I would be using would always be centered around the origin $(0, 0)$ I can use a simplified version of the Gaussian distribution equation. This is as follows: \\ \bk
            
            \begin{gather*}
                H_{ij} = \frac{1}{2\pi\sigma^2} \exp \frac{-(x^2 + y^2)}{\sigma^2}
            \end{gather*}
            
            \BK
            I can afford to remove the $(i - (k + 1))$ section due to the fact that I am not having to calculate the Gaussian distribution at a non-centered location. One notable thing to mention is that in many cases it is not necessary to calculate the Gaussian kernel by hand and an approximation can be used. The example below is the approximation when $\sigma$ has a value of 1. \\ \bk
            
            \begin{gather*}
                B = \frac{1}{159} \begin{bmatrix} 
                2 & 4 & 5 & 4 & 2\\
                4 & 9 & 12 & 9 & 4\\
                5 & 12 & 15 & 12 & 5\\
                4 & 9 & 12 & 9 & 4\\
                2 & 4 & 5 & 4 & 2
                \end{bmatrix} * A
            \end{gather*}
            \bk
            
            \paragraph{Convolution Operation} \mbox{} \\
            Convolution is the method at which most image manipulation is achieved. It evolves taking a altering kernel and a kernel of the original image and then combines the two through convolution. The generalised equation for this is as follows. \\ \bk
            
            \begin{gather*}
            {\displaystyle {\begin{bmatrix}x_{11}&x_{12}&\cdots &x_{1n}\\x_{21}&x_{22}&\cdots &x_{2n}\\\vdots &\vdots &\ddots &\vdots \\x_{m1}&x_{m2}&\cdots &x_{mn}\\\end{bmatrix}}*{\begin{bmatrix}y_{11}&y_{12}&\cdots &y_{1n}\\y_{21}&y_{22}&\cdots &y_{2n}\\\vdots &\vdots &\ddots &\vdots \\y_{m1}&y_{m2}&\cdots &y_{mn}\\\end{bmatrix}}=\sum _{i=0}^{m-1}\sum _{j=0}^{n-1}x_{(m-i)(n-j)}y_{(1+i)(1+j)}}
            \end{gather*} \bk

            To give a more comprehensive example this can be simplified down to:

            \begin{gather*}
                \displaystyle \left({\begin{bmatrix}a&b&c\\d&e&f\\g&h&i\end{bmatrix}}*{\begin{bmatrix}1&2&3\\4&5&6\\7&8&9\end{bmatrix}}\right)\\  \\
                \rightarrow{} (i\cdot 1)+(h\cdot 2)+(g\cdot 3)+(f\cdot 4)+(e\cdot 5)+(d\cdot 6)+(c\cdot 7)+(b\cdot 8)+(a\cdot 9)
            \end{gather*}

            \bk
            The simplest way of thinking of this is that you are performing matrix multiplication on a two matrices except one of them has been flipped both vertically and horizontally. Mapping the point [2, 2] to [0, 0].

            \subsubsection{Second Interview}
            \large
            Now that I have done some more research into the various ways there are to complete this task I have formed some more questions to ask my end user to get a solid and
            defined list of objectives for the program. AI will couple this with my research to form a complete plan to form said objectives. As well as this however the second interview
            will allow me to correct any inaccurate questions that where asked in the initial interview. This is because after I received my initial responses I realised that I
            needed to be more clear with what I was asking and the information that I wanted back. \\
            \bk
            
            \begin{enumerate}
                \item {\bf{Bobbert?}} \\
                \bk
                bobbert.
                \item {\bf{Cobbert?}} \\
                \bk
                cobbert.
                \item {\bf{Dobbert?}} \\
                \bk
                dobbert.
                \item {\bf{Fobbert?}} \\
                \bk
                Fobbert.
                \item {\bf{Norbert?}} \\
                \bk
                norbert
                \item {\bf{Dilbert?}} \\
                \bk
                dilbert.
                \item {\bf{Bobbert?}} \\
                \bk
                bobbert.
            \end{enumerate}

            \subsubsection{Evaluation of Second Interview}
            After conducting this second interview I feel I now have a firm understanding of what I need to achieve with this program. I will also take this opportunity to create a prototype of the 
            the different parts of the program to gauge the difficulty of the program and any problems I may encounter before moving onto the final solution. \\ \bk
            Apart from that however I feel the interview went\dots % add to this

        \subsection{Prototyping}
        \subsubsection{Prototype Objectives} 
        Before I begin the creation of my prototypes I will create a list of sections I wish to complete by the end. This will allow me to keep perspective and make sure that the prototype remains on track. I have decided that the parts of my final solution are:
        
        \begin{itemize}
            \item A version of edge detection
            \item A graph class with basic traversal
            \item A forms interface for showing images
        \end{itemize} \bk
        

        \subsubsection{Edge Detection}
        For the example of edge detection which I am going to prototype I have chosen Canny Edge Detection, this is the most common of the types of edge detection and is relatively simple. It is also widely documented which allows me to focus more on the application and less on the finding of resources. \\ \bk

        Before I begin, there are a couple of key features that need to be mentioned. The first is how I handle building the image kernel. For example when the center pixel is on the edge of the image, you will have some non existent pixels as part of the image kernel. To combat this there are several methods:
        
        \begin{enumerate}
            \item Extension - The nearest border pixels to the chosen pixel are extended in order to fill the gaps. The corner pixels are extended at 90 deg. Others are extended in straight lines.
            \item Wrapping - The pixels for the unknown ones are taken from the opposite side of the image. For example it it was 1 off the top the first pixel from the bottom would be used.
            \item Mirroring - The image is mirrored at the edges doubling up the total image.
            \item Constants - Any pixels in the kernel which are not contained in the image are given a default value, this is usually grey or black depending on the application.
            \item Duplication - Similar to above any pixels which are not contained are set to the value of the center pixel in the kernel.
        \end{enumerate} \bk
        
        \begin{figure}[H]
            \centering
            \subfloat[\centering Wrapping]{{\includegraphics[width=4.5cm]{images/kernelExamples/wrap.png}}}
            \qquad
            \subfloat[\centering Mirroring]{{\includegraphics[width=4.5cm]{images/kernelExamples/mirror.png}}}
            \\ \BK
            \qquad
            \subfloat[\centering Extension]{{\includegraphics[width=2.5cm]{images/kernelExamples/extend.png}}} \space
            \qquad
            \subfloat[\centering Constants]{{\includegraphics[width=2.5cm]{images/kernelExamples/constant.png}}}
            \qquad
            \subfloat[\centering Duplication]{{\includegraphics[width=2.5cm]{images/kernelExamples/clone.png}}}
        \end{figure}
        

        For this part of the prototype I have decide to go with the duplication option, this is due to the fact that it is one of the easier and quicker methods to implement as well as being suitable for the edge detection use case. \\ \bk
        
        \begin{figure}[H]
            \centering
            \includegraphics[width=5cm]{images/edgeDetectionPrototype/in.jpg}
            \caption{Original Image}
            \label{fig:proto_original}
        \end{figure}
        
        \paragraph{1. Converting to Black and White} \mbox{} \\
        The first part of the edge detection is to convert the image to black and white. This is because if the image is in colour then you would have to either perform edge detection on each of the colour sections and then somehow combine them, or take a single colour value to base the conversion off of. As previously mentioned this can be accomplished through many means, the most common as explained in \textit{1.5.1 Black and White Filter}. The version which I have decided to use for this prototype is the industry standard Y\textsuperscript{'}UV conversion. \\ \bk
        
        The implementation in code of this is as below:
        \begin{cscode}
public double[,] BWFilter(Bitmap image)
{
    double[,] result = new double[image.Height, image.Width];

    for (int i = 0; i < image.Height; i++)
    {
        for (int j = 0; j < image.Width; j++)
        {
            Color c = image.GetPixel(j, i);
            double value = c.R * 0.299 + c.G * 0.587 + c.B * 0.114;

            result[i, j] = Bound(0, 255, value);
        }
    }

    return result;
}
        \end{cscode}
        
        This takes the original image in Bitmap form and then instantiates an array with the dimensions of the input image, this will serve going forward as the array as to which all changes will be based from. I learnt from this prototype early on that when calculating the values is is better to use the exact ones from the previous stage. This is because if all the values where compressed to within image specifications ($0 \leq x \leq 25$) you would loose definition and precision causing later calculation so be incorrect. Once this section has run through every pixel in the image and converted it to a black and white value the subroutine returns the double array with the black and white values. The result of this on the input \textit{figure \ref{fig:proto_original}} is: \\ \bk
        
        \begin{figure}[H]
            \centering
            \includegraphics[width=5cm]{images/edgeDetectionPrototype/a.jpg}
            \caption{Black and White Filter}
            \label{fig:proto_bwfilter}
        \end{figure} \bk
        
        \paragraph{2. Gaussian Filter} \mbox{} \\
        The next step of canny edge detection is applying the Gaussian filter. This is to ensure that any noise that is contained within the image is removed. This is because if there are stray pixels in the center of the image this can cause an edge to form when in fact there isn't one. This is the first operation in edge detection which requires convolution as explained in \textit{1.5.1 Gaussian Filter}. To accomplish this the following code was used: \\ \bk
        
        \begin{cscode}
public double[,] GaussianFilter(double sigma, int kernelSize, double[,] imageArray)
{
    double[,] result = new double[imageArray.GetLength(0), imageArray.GetLength(1)];

    Matrix gaussianKernel = GetGaussianKernel(kernelSize, sigma);

    for (int i = 0; i < result.GetLength(0); i++)
    {
        for (int j = 0; j < result.GetLength(1); j++)
        {
            Matrix imageKernel = BuildKernel(j, i, kernelSize, imageArray);
            double sum = Matrix.Convolution(imageKernel, gaussianKernel);
            result[i, j] = sum;
        }
    }

    return result;
}
        
public Matrix GetGaussianKernel(int k, double sigma)
{
    double[,] result = new double[k, k];
    int halfK = k / 2;

    double sum = 0;

    int cntY = -halfK;
    for (int i = 0; i < k; i++)
    {
        int cntX = -halfK;
        for (int j = 0; j < k; j++)
        {
            result[halfK + cntY, halfK + cntX] = GetGaussianDistribution(cntX, cntY, sigma);
            sum += result[halfK + cntY, halfK + cntX];
            cntX++;
        }
        cntY++;
    }

    for (int i = 0; i < k; i++) for (int j = 0; j < k; j++) result[i, j] /= sum;
    return new Matrix(result);
}
        \end{cscode}
        
        Again this subroutine follows a similar layout to the rest in this prototype, it iterates though each pixel in the image and apply some equation. In this case as stated above it is performing convolution of a matrix which is a sub section of the original image. It is convoluting this with the Gaussian kernel though the means described in \textit{1.5.1 Convolution Operation}. The code for the convolution operation can be seen at \textit{5.1.1 Lines 586 through 612} and the Gaussian distribution lambda function can be found \textit{5.1.1 Line 554}. Another learning experience here was how if the image is sufficiently large then the kernel does not have as much of an effect at blurring the image and removing noise. It may be beneficial in the final program to reduce the image to a smaller size or perhaps change the sigma and kernel size. The output of this subroutine is: \\ \bk

        \begin{figure}[H]
            \centering
            \includegraphics[width=5cm]{images/edgeDetectionPrototype/b.jpg}
            \caption{Gaussian Filter}
            \label{fig:proto_guaussian}
        \end{figure} \bk
        
        \paragraph{3. Calculation of XY Gradients} \mbox{} \\
        The first edge picking stage of canny edge detection is the calculation of the gradients of the image in both the X axis and the Y axis. In order to achieve this two more kernels are used. They are known as the Sobel operators. \\
        \begin{gather*}
            {\displaystyle M_{y}={\begin{bmatrix}+1&0&-1\\+2&0&-2\\+1&0&-1\end{bmatrix}}\quad {\text{and}}\quad M_{x}={\begin{bmatrix}+1&+2&+1\\0&0&0\\-1&-2&-1\end{bmatrix}}}
        \end{gather*} \bk
        
        The code which is used to perform this section of the canny edge detection is as follows, note that for the gradient in Y the matrix is replaced with the Y matrix and its code can be seen at \textit{5.1.1 Lines 416 through 432}. \\ \bk
        
        \begin{cscode}
public double[,] CalculateGradientX(double[,] imageArray)
{
    double[,] result = new double[imageArray.GetLength(0), imageArray.GetLength(1)];

    Matrix sobelX = new Matrix(new double[,] {
        { 1, 2, 1 },
        { 0, 0, 0 },
        { -1, -2, -1 },
    });

    for (int i = 0; i < imageArray.GetLength(0); i++)
    {
        for (int j = 0; j < imageArray.GetLength(1); j++)
        {
            Matrix imageKernel = BuildKernel(j, i, 3, imageArray);
            result[i, j] = Matrix.Convolution(imageKernel, sobelX);
        }
    }

    return result;
}
        \end{cscode}
        
        Same as the Gaussian filter the convolution operation is applied to both of these matrices. The kernels that are used are build from the image with the center $(i,j)$ same as the previous step. This is when it becomes beneficial to use the duplication method for the kernel building. Since the gradient is dependent on the surrounding pixels using the pixel itself prevents false edges from appearing. The two separate gradient kernels produce the following images:
        
        \begin{figure}[H]
            \centering
            \subfloat[Gradient in X]{\includegraphics[width=5cm]{images/edgeDetectionPrototype/c.jpg}}
            \label{fig:proto_gradX}
            \qquad
            \subfloat[Gradient in Y]{\includegraphics[width=5cm]{images/edgeDetectionPrototype/d.jpg}}
            \label{fig:proto_gradY}
        \end{figure} \bk
        
        These two images represent the cases where in the image there is a change in the value of the pixels. The brighter the white the more different two given pixels are. We can combine these two to give a total image of all gradient changes. Find image below, while this is useful to look at from a human perspective it is not the most useful in edge detection and in fact we will need both the raw 2D double arrays from each gradient calculation to move onto the next step.
        
        \begin{figure}[H]
            \centering
            \includegraphics[width=5cm]{images/edgeDetectionPrototype/e.jpg}
            \caption{Gaussian Filter}
            \label{fig:proto_gradTot}
        \end{figure} \bk
        
        \paragraph{4. Gradient Direction} \mbox{} \\
        Now that the gradient values have been calculated we can move onto working out which direction the gradient is traveling. This is done via the use of the $2^{nd}$ argument arc-tangent. The definition of the $2^{nd}$ argument arc-tangent is defined as the angle in the Euclidean plane, given in radians, between the positive $x$ axis and the ray from the origin to the point $(x,y)$. Once this is calculated this will allow the program to see in which direction the gradient is traveling in the image. As well as this is also allows us to see how sharp the change is from one to the other, this is how we can decide if there is an edge there. The code to calculate the $2^{nd}$ argument arc-tangent is simple since all is needed is to iterate over the entire image. The code for this can be seen at \textit{5.1.1 Lines 379 through 384.}
        
        \begin{cscode} 
public double[,] CalculateTheta(double[,] gradX, double[,] gradY)
{
    double[,] result = new double[gradX.GetLength(0), gradX.GetLength(1)];
    for (int i = 0; i < gradX.GetLength(0); i++) for (int j = 0; j < gradX.GetLength(1); j++) result[i, j] = Math.Atan2(gradY[i, j], gradX[i, j]);
    return result;
}
        \end{cscode}
        
        This however will return an array with values which are in the range of -$\pi$ to $\pi$ therefor in order to create an image to visualise the result a linear transformation must be used which can be calculated as the equation of a line. The derived equation is $\frac{128}{2\pi}x + 128$ where x is the value of theta. Once converted the output of this stage is as follows.
        \begin{figure}[H]
            \centering
            \includegraphics[width=5cm]{images/edgeDetectionPrototype/f.jpg}
            \caption{Gaussian Filter}
            \label{fig:proto_gradDir}
        \end{figure} \bk

        \paragraph{5. Gradient Magnitude Threshold} \mbox{} \\
        Once both the combined gradient and gradient directions have been calculate the next step in the process is working out which parts of the edge detected image are noise and which are not. In order to do this the combined gradients and the direction are taken into account and similar to before we build a kernel of the surrounding pixels of the image. The first part of this however is to convert the values in radians to values in degrees, to do this we run all through all values and convert them first. This can be seen \textit{Lines 372 through 377}.
        
        \begin{cscode}
public double[,] ConvertThetaToDegrees(double[,] thetaArray)
{
    double[,] result = new double[thetaArray.GetLength(0), thetaArray.GetLength(1)];
    for (int i = 0; i < thetaArray.GetLength(0); i++) for (int j = 0; j < thetaArray.GetLength(1); j++) result[i, j] = 180 * Math.Abs(thetaArray[i, j]) / Math.PI;
    return result;
}
        \end{cscode}
        
        Once all values are in degrees this becomes easier to deal with since there is less data lost to floating point arithmetic. Now that the angles are in degrees they are compared to predefined values as shown in the code. Depending which if the categories the pixel in question falls into the kernel is then used to decide whether that pixel will be set to black or not. Since this is the first filtering pass it is rather blunt and will not remove all of the noise in the image, this will come at a later stage through the use of min max threshold. \\ \bk

        The main part of the edge detection that this portion of the code completes is removing parts of the image which have random lines in the image. This is due to us having a "made up" direciton of where the line is  


        \subsection{Objectives}
        \large
        
        % Tips for objectives
        
        % 1. Use numbered objectives to allow them to be refer ed back to
        % 2. Don't mention programming techniques
        % 3. Objectives for the program not the programmer
        
        After conducting the initial and second interviews and reflecting upon the results of my research I have formed a list of objectives that the program must meet to be considered 
        complete. As well as the base objectives I have also, with help from my end user, come up with extensions which will increase the effectiveness of my solution overall. \\
        \bk
        
        \renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}}
        \renewcommand{\labelenumiii}{\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}}
        \renewcommand{\labelenumiv}{\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}.\arabic{enumiv}}
        
        \begin{enumerate}
            \item The Program must have way to input a Map
            \begin{enumerate}
                \item The Program should be able to parse a map from a file, including
                \begin{enumerate}
                    \item A photograph of an map
                    \item A screenshot of an existing map
                    \item A hand drawing of suitable quality
                \end{enumerate}
                \item When the user inputs a map, the program will ask them
                \begin{enumerate}
                    \item What type of map they are inputting
                    \item Whether this is the correct image
                    \item Whether they want the image deleted after edge detection
                    \item Whether they would like the image to be stored in a binary file \\
                    \emph{These are just some examples of prompts}
                \end{enumerate}
                \item The inputted map should be converted into a graph
                \begin{enumerate}
                    \item The map (in graph form) should be able to be traversed
                    \item The map (in graph form) should be able to be formed into a MST
                \end{enumerate}
                
                \item If any error occurs during the map input process an appropriate error should be displayed and the program should continue to run
            \end{enumerate}

            \item The Program must perform canny edge detection   
            \begin{enumerate}
                \item At each stage of the edge detection an image should be produced
                \item Between each stage the user should be able to repeat the last step in order to change parameters.\\
                \emph{The user should be able to change (at various stages):} 
                \begin{enumerate}
                    \item The sigma value of the Gaussian elimination
                    \item The lower threshold value
                    \item The higher threshold value
                    \item The Gaussian kernel size
                    \item The black and white filter ratios
                    \item The amount of times embossing is performed
                    \item The times de-blocking should be performed
                \end{enumerate}
                \item The edge detection must have the option to be multi threaded.
                \item The edge detection must have the option to be single threaded
            \end{enumerate}
            
            \item The Program must overlay the detected roads onto the original image
            \begin{enumerate}
                \item The result of the edge detection will be shown to the user before road detection
                \item The program will perform road detection
                \begin{enumerate}
                    \item The image should have the option to be inverted
                    \item A filling algorithm should be applied to the image
                    \begin{enumerate}
                        \item There should be the option of using a stack
                        \item There should be the option of using a queue
                    \end{enumerate}
                    \item The percentage threshold for non roads much be changeable by the user
                    \item The total filled image must be displayed to the user
                    \item The singled out roads and paths must be shown to the user
                \end{enumerate}
                
            \end{enumerate}
            
            \item The Program must allow Map Traversal
            \begin{enumerate}
                \item There should be Multiple Traversal Algorithms Available to be chosen from.
                    \begin{enumerate}
                        % https://en.wikipedia.org/wiki/Category:Graph_algorithms
                        \item The Program should implement Routing Algorithms 
                        \begin{enumerate}
                            \item This includes Dijkstra's algorithm
                            \item This includes A*
                            \item This includes Shortest Path Faster Algorithm (SPFA)
                        \end{enumerate}
                        % https://en.wikipedia.org/wiki/Category:Search_algorithms
                        \item The Program should Implement Searching Algorithms
                        \begin{enumerate}
                            \item This includes BFS (Breadth-first search)
                            \item This includes DFS (Depth-first search)
                            \item This includes Greedy Best-First Search
                        \end{enumerate}
                        \item The program should implement a Minimum spanning tree
                        \begin{enumerate}
                            \item It should implement Primm's algorithm
                            \item It should implement Kruskal's algorithm
                        \end{enumerate}
                    \end{enumerate}
                \item Depending on the option that the user chooses they can either
                \begin{enumerate}
                    \item Decide a specific algorithm to use
                    \item Have the program compute all and use the most efficient one
                    \item Have the program compute all and let the user select one
                    \begin{enumerate}
                        \item The time for each should be displayed
                        \item The length of each should be displayed
                        \item The node count of each should be displayed
                    \end{enumerate}
                \end{enumerate}
            \end{enumerate}
            
            \item The Program must have a Clear and Simplistic GUI
            \begin{enumerate}
                \item At a glance the user should be able to ascertain which step they are at in the process.
                \item Whenever a forms is displayed it should not serve more than one purpose
            \end{enumerate}          

            \item The program must implement abstract data types
            \begin{enumerate}
                \item The program must implement a matrix class
                \begin{enumerate}
                    \item The program must be able to perform basic operations
                    \begin{enumerate}
                        \item Perform matrix multiplication
                        \item Perform matrix addition
                        \item Perform matrix subtraction
                        \item Perform scalar multiplication
                        \item Perform matrix minimisation
                \end{enumerate}
                \item The program must be able to find the determinant of a matrix
                \item The program must be able to find the inverse of a matrix
                \item The program must be able to apply the convolution operation
                \end{enumerate}
                
            \end{enumerate}
            \bk
        \end{enumerate}  
        \vspace{1cm}
        \centerline{\large\textbf{Extension Objectives}}
        \vspace{1cm}

        \begin{enumerate}[resume]
            \item The program should be able to output
            \begin{enumerate}
                \item The map in a binary file format
                \begin{enumerate}
                    \item This file can be saved
                    \item This file can be re-read and re-routed
                \end{enumerate}
                \item The routed map with path drawn on it
            \end{enumerate}
            \item If the user chooses, the program should be able to run a web server
            \begin{enumerate}
                \item The web version should have a similar speed to the local version
                \item The web version should have a similar feature set to the local version \\
                \emph{This only applies to features that are possible to work in the web, they may be displayed differently that the local application due to different frameworks}
                \item The web interface should be easy to use and intuitive
                % \item Have it scale to device sizes (very very hard)
            \end{enumerate} 
        \end{enumerate}

        \bk

        % sufficiently well modelled ti be of use in subsequent stages
        % Outline the structure of the program
        % not all modeling needs to go in this section
        % class diagram and equations to be used
        % mockup of the interface (less vital)
        \subsection{Modeling}
        \bk

\end{flushleft}